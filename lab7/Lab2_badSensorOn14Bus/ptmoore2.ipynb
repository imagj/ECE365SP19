{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Detecting Bad Sensors in Power System Monitoring\n",
    "\n",
    "In this lab, our goal is to detect bad sensor data measured on the IEEE 14 bus test\n",
    "system shown below. The power flow equations that couple the voltages and power flows are \n",
    "nonlinear in nature, as discussed in class. We will load the sensor data from the\n",
    "file 'sensorData14Bus.csv', and utilize SVM to perform the bad data detection.\n",
    "We aim to understand how various parameters such as the nature of the corrupt data,\n",
    "the number of corrupt data, etc., affect our abilities to classify the data.\n",
    "\n",
    "<img src=\"IEEE14bus.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to call the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data \n",
    "\n",
    "Load the sensor data from the IEEE 14 bus test system, that has 14 buses\n",
    " and 20 branches. The data has been generated by adding a small noise\n",
    " to feasible voltages and power flows.\n",
    "     \n",
    "     Columns 1-14 contain bus voltage magnitudes.\n",
    "     \n",
    "     Columns 15-28 contain bus voltage phase angles.\n",
    "     \n",
    "     Columns 29-48 contain real power flow on all branches.\n",
    "     \n",
    "     Columns 49-68 contain reactive power flow on all branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    "\n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curroption Models \n",
    "\n",
    "Intentionally corrupt the first 'nCorrupt' rows of the data by adding\n",
    " a quantity to one or two sensor measurements that is not representative of\n",
    " our error model. We aim to study what nature of corruption is easier\n",
    " or difficult to detect.\n",
    " Specifically, we shall study 3 different models:\n",
    " \n",
    "     1. 'corruptionModel' = 1 : Add a random number with a bias to one of the measurements.\n",
    "     \n",
    "     2. 'corruptionModel' = 2 : Add a random number without bias to one of the measurements.\n",
    "     \n",
    "     3. 'corruptionModel' = 3 : Add a random number with a bias to both the measurements.\n",
    "     \n",
    "In all these cases, we will multiply the sensor data by either a uniform or a normal random number multiplied by 'multiplicationFactor'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 1\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: 2*ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: 2*ii + 1\n",
    "\n",
    "realPowerColumn = lambda ii: 2 * ii \\\n",
    "                             + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: 1 + 2 * ii \\\n",
    "                             + 2*np.shape(busesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 2\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is always a good practice to scale your data to run SVM. Notice that we are\n",
    " cheating a little when we scale the entire data set 'X', because our training and\n",
    " test sets are derived from 'X'. Ideally, one would have to scale the training\n",
    " and test sets separately. Create the appropriate labels and shuffle the lists 'X' and 'Y' together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the first lab that 'test_size' determines what fraction of the data becomes your test set.\n",
    "\n",
    "## Task 1 (10 points)\n",
    "\n",
    "Split the dataset into two parts: training and testing.\n",
    "Store the training set in the variables 'trainX' and 'trainY'.\n",
    " Store the testing set in the variables 'testX' and 'testY.\n",
    " Reserve 20% of the data for testing.\n",
    "The function 'train_test_split' may prove useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled and split the data into two parts.\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(\"Scaled and split the data into two parts.\")\n",
    "\n",
    "# print(\"Scaled and split the data into two parts:\")\n",
    "#\n",
    "# nTrain = np.shape(trainX)[0]\n",
    "# nTest = np.shape(testX)[0]\n",
    "# \n",
    "# print(\"Neural network will train on %d data points, and test on %d data points.\" % (trainX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (10 points)\n",
    "\n",
    " Define the support vector machine classifier and train on the variables 'trainX' and 'trainY'. Use the SVC library from sklearn.svm. Only specify three hyper-parameters: 'kernel', 'degree', and 'max_iter'. Limit the maximum number of iterations to 100000 at the most. Set the kernel to be a linear classifier first. You may have to change it to report the results with other kernels. The parameter 'degree' specifies the degree for polynomial kernels. This parameter is not used for other kernels. The functions 'svm.SVC' and 'fit' will prove useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=100000, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your code here\n",
    "SVCclassifier = svm.SVC(degree=2, kernel='linear', max_iter=100000)\n",
    "SVCclassifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (10 points)\n",
    "\n",
    "Predict the labels on the 'testX' dataset and store them in 'predictY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "predictY = SVCclassifier.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (10 points)\n",
    "\n",
    "Print the 'classification_report' to see how well 'predictY' matches with 'testY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98       692\n",
      "         1.0       0.91      1.00      0.95       308\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1000\n",
      "   macro avg       0.96      0.98      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(classification_report(predictY, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print svm's internal accuracy score as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.0 \b%\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(\"Accuracy =\", SVCclassifier.score(testX, testY) * 100, \"\\b%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "We would like to compare 'classification_report' with this score for various runs. Let us consider the following cases: \n",
    "\n",
    "### Case 1:\n",
    "\n",
    "Only have sensor measurements from the first 5 branches. Choose option 1 in the 'columnsToCorruptOption'. Examine how well linear kernels perform when 'corruptionModel' = 1, 'corruptionModel' = 2, and 'corruptionModel'= 3. In case linear kernels do not perform well, you may try 'rbf' or polynomial kernels with degree 2.\n",
    "\n",
    "### Case 2:\n",
    "\n",
    "Choose 'corruptionModel = 1' with 'linear' kernel. Does it pay to monitor voltage magnitudes than power flows? In other words, do you consistently get better results when you choose 'columnsToCorruptOption' as 2? Make these judgements using the average score of at least 5 runs.\n",
    "\n",
    "\n",
    "#### Your task is to investigate the above two cases. You may add a few 'Markdown' and 'Code' cells below with your comments, code, and results. You can also report your results as a pandas DataFrame. You are free to report your results in your own way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corruptionModel = 1\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 15\n",
      "Scaled and split the data into two parts.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.66      0.79       975\n",
      "         1.0       0.06      0.80      0.11        25\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      1000\n",
      "   macro avg       0.52      0.73      0.45      1000\n",
      "weighted avg       0.97      0.67      0.78      1000\n",
      "\n",
      "Accuracy = 66.60000000000001%\n",
      "\n",
      "\n",
      "corruptionModel = 2\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 15\n",
      "Scaled and split the data into two parts.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.64      0.78       996\n",
      "         1.0       0.01      1.00      0.02         4\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1000\n",
      "   macro avg       0.51      0.82      0.40      1000\n",
      "weighted avg       1.00      0.64      0.78      1000\n",
      "\n",
      "Accuracy = 64.4%\n",
      "\n",
      "\n",
      "corruptionModel = 3\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 15\n",
      "Scaled and split the data into two parts.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96       722\n",
      "         1.0       0.83      1.00      0.91       278\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1000\n",
      "   macro avg       0.91      0.96      0.93      1000\n",
      "weighted avg       0.95      0.94      0.94      1000\n",
      "\n",
      "Accuracy = 94.3%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for corruptionModel in range (1, 4):\n",
    "    print(\"corruptionModel =\", corruptionModel)\n",
    "    nBuses = 14\n",
    "    nBranches = 20\n",
    "    # Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "    # The '-1' makes them columns as per Python's convention of starting to number\n",
    "    # from 0.\n",
    "    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "    # Select the branches that you monitor.\n",
    "    branchesToSample = np.array([1, 2, 3, 4, 5]) - 1\n",
    "    columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                         branchesToSample + 48))\n",
    "    # Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "    # specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "    # separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "    # with each column typecast as 'np.float32'.\n",
    "    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                      usecols=np.concatenate((busesToSample, columnsForBranches)),\n",
    "                      max_rows=5000)\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "    print(\"Number of data points = %d, number of features = %d\"\n",
    "          % (nDataPoints, nFeatures))\n",
    "    # Choose a corruption model.\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "    multiplicationFactor = 0.5\n",
    "    # Choose which data to tamper with, that can be a voltage magnitude,\n",
    "    # voltage phase angle, real power flow on a branch, reactive power flow\n",
    "    # on a branch. We create functions to extract the relevant column to\n",
    "    # corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "    voltageMagnitudeColumn = lambda ii: 2*ii\n",
    "\n",
    "    voltageAngleColumn = lambda ii: 2*ii + 1\n",
    "\n",
    "    realPowerColumn = lambda ii: 2 * ii \\\n",
    "                                 + 2*np.shape(busesToSample)[0]\n",
    "    reactivePowerColumn = lambda ii: 1 + 2 * ii \\\n",
    "                                 + 2*np.shape(busesToSample)[0]\n",
    "    # Encode two different kinds of columns to corrupt.\n",
    "    # Option 1: Corrupt real power columns only.\n",
    "    # Option 2: Corrupt real power and voltage magnitude.\n",
    "    columnsToCorruptOption = 1\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "    # Corrupt the data appropriately, given the options.\n",
    "    for index in range(nCorrupt):\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    # Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "    # 0's for the rest.\n",
    "    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "    # Shuffle the features and the labels together.\n",
    "    XY = list(zip(X, Y))\n",
    "    np.random.shuffle(XY)\n",
    "    X, Y = zip(*XY)\n",
    "    # Enter your code here\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    print(\"Scaled and split the data into two parts.\")\n",
    "    # Enter your code here\n",
    "    if corruptionModel == 3:\n",
    "        kernaltype = 'linear'\n",
    "    else:\n",
    "        kernaltype = 'rbf'\n",
    "    SVCclassifier = svm.SVC(degree=2, kernel=kernaltype, gamma='auto', max_iter=100000)\n",
    "    SVCclassifier.fit(trainX, trainY)\n",
    "    # Enter your code here\n",
    "    predictY = SVCclassifier.predict(testX)\n",
    "    # Enter your code here\n",
    "    print(classification_report(predictY, testY))\n",
    "    # Enter your code here\n",
    "    print(\"Accuracy =\", SVCclassifier.score(testX, testY) * 100, \"\\b%\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "What I notice above is that it is much easier to predict error when more numbers are off. The accuracy dramtically lowers when we only corrupt real power columns, but the accuracy still stays pretty high for the third model. My guess is because the third model corrupts multiple measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1 accuracy score 1  = 66.7%\n",
      "Option 1 accuracy score 2  = 68.8%\n",
      "Option 1 accuracy score 3  = 65.8%\n",
      "Option 1 accuracy score 4  = 67.5%\n",
      "Option 1 accuracy score 5  = 66.2%\n",
      "Option 1 accuracy score 6  = 65.3%\n",
      "Option 1 accuracy score 7  = 65.5%\n",
      "Option 1 accuracy score 8  = 64.5%\n",
      "Option 1 accuracy score 9  = 67.7%\n",
      "Option 1 accuracy score 10  = 66.2%\n",
      "Option 2 accuracy score 1  = 97.0%\n",
      "Option 2 accuracy score 2  = 97.7%\n",
      "Option 2 accuracy score 3  = 97.5%\n",
      "Option 2 accuracy score 4  = 97.8%\n",
      "Option 2 accuracy score 5  = 97.39999999999999%\n",
      "Option 2 accuracy score 6  = 97.2%\n",
      "Option 2 accuracy score 7  = 97.2%\n",
      "Option 2 accuracy score 8  = 96.7%\n",
      "Option 2 accuracy score 9  = 96.7%\n",
      "Option 2 accuracy score 10  = 95.8%\n",
      "\n",
      "\n",
      "\n",
      "Option 1 average accuracy = 66.42%\n",
      "Option 2 average accuracy = 97.10000000000001%\n"
     ]
    }
   ],
   "source": [
    "CorruptionScore1 = 0\n",
    "maxLoops = 10\n",
    "for loops in range(maxLoops):\n",
    "    nBuses = 14\n",
    "    nBranches = 20\n",
    "    # Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "    # The '-1' makes them columns as per Python's convention of starting to number\n",
    "    # from 0.\n",
    "    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "    # Select the branches that you monitor.\n",
    "    branchesToSample = np.array([1, 2, 3, 4, 5]) - 1\n",
    "    columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                         branchesToSample + 48))\n",
    "    # Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "    # specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "    # separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "    # with each column typecast as 'np.float32'.\n",
    "    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                      usecols=np.concatenate((busesToSample, columnsForBranches)),\n",
    "                      max_rows=5000)\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    # Choose a corruption model.\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "    corruptionModel = 1\n",
    "    multiplicationFactor = 0.5\n",
    "    # Choose which data to tamper with, that can be a voltage magnitude,\n",
    "    # voltage phase angle, real power flow on a branch, reactive power flow\n",
    "    # on a branch. We create functions to extract the relevant column to\n",
    "    # corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "    voltageMagnitudeColumn = lambda ii: 2*ii\n",
    "\n",
    "    voltageAngleColumn = lambda ii: 2*ii + 1\n",
    "\n",
    "    realPowerColumn = lambda ii: 2 * ii \\\n",
    "                                 + 2*np.shape(busesToSample)[0]\n",
    "    reactivePowerColumn = lambda ii: 1 + 2 * ii \\\n",
    "                                 + 2*np.shape(busesToSample)[0]\n",
    "    # Encode two different kinds of columns to corrupt.\n",
    "    # Option 1: Corrupt real power columns only.\n",
    "    # Option 2: Corrupt real power and voltage magnitude.\n",
    "    columnsToCorruptOption = 1\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "    # Corrupt the data appropriately, given the options.\n",
    "    for index in range(nCorrupt):\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    # Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "    # 0's for the rest.\n",
    "    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "    # Shuffle the features and the labels together.\n",
    "    XY = list(zip(X, Y))\n",
    "    np.random.shuffle(XY)\n",
    "    X, Y = zip(*XY)\n",
    "    # Enter your code here\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    # Enter your code here\n",
    "    SVCclassifier = svm.SVC(degree=2, kernel='linear', gamma='auto', max_iter=100000)\n",
    "    SVCclassifier.fit(trainX, trainY)\n",
    "    # Enter your code here\n",
    "    predictY = SVCclassifier.predict(testX)\n",
    "    # Enter your code here\n",
    "    # Enter your code here\n",
    "    CorruptionScore1 += SVCclassifier.score(testX, testY) * 100\n",
    "    print(\"Option 1 accuracy score\", (loops + 1), \" =\", SVCclassifier.score(testX, testY) * 100, \"\\b%\")\n",
    "CorruptionScore2 = 0\n",
    "for loops in range(maxLoops):\n",
    "    nBuses = 14\n",
    "    nBranches = 20\n",
    "    # Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "    # The '-1' makes them columns as per Python's convention of starting to number\n",
    "    # from 0.\n",
    "    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "    # Select the branches that you monitor.\n",
    "    branchesToSample = np.array([1, 2, 3, 4, 5]) - 1\n",
    "    columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                         branchesToSample + 48))\n",
    "    # Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "    # specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "    # separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "    # with each column typecast as 'np.float32'.\n",
    "    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                      usecols=np.concatenate((busesToSample, columnsForBranches)),\n",
    "                      max_rows=5000)\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    # Choose a corruption model.\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "    corruptionModel = 1\n",
    "    multiplicationFactor = 0.5\n",
    "    # Choose which data to tamper with, that can be a voltage magnitude,\n",
    "    # voltage phase angle, real power flow on a branch, reactive power flow\n",
    "    # on a branch. We create functions to extract the relevant column to\n",
    "    # corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "    voltageMagnitudeColumn = lambda ii: 2*ii\n",
    "\n",
    "    voltageAngleColumn = lambda ii: 2*ii + 1\n",
    "\n",
    "    realPowerColumn = lambda ii: 2 * ii \\\n",
    "                                 + 2*np.shape(busesToSample)[0]\n",
    "    reactivePowerColumn = lambda ii: 1 + 2 * ii \\\n",
    "                                 + 2*np.shape(busesToSample)[0]\n",
    "    # Encode two different kinds of columns to corrupt.\n",
    "    # Option 1: Corrupt real power columns only.\n",
    "    # Option 2: Corrupt real power and voltage magnitude.\n",
    "    columnsToCorruptOption = 2\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "    # Corrupt the data appropriately, given the options.\n",
    "    for index in range(nCorrupt):\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    # Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "    # 0's for the rest.\n",
    "    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "    # Shuffle the features and the labels together.\n",
    "    XY = list(zip(X, Y))\n",
    "    np.random.shuffle(XY)\n",
    "    X, Y = zip(*XY)\n",
    "    # Enter your code here\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    # Enter your code here\n",
    "    SVCclassifier = svm.SVC(degree=2, kernel='linear', gamma='auto', max_iter=100000)\n",
    "    SVCclassifier.fit(trainX, trainY)\n",
    "    # Enter your code here\n",
    "    predictY = SVCclassifier.predict(testX)\n",
    "    # Enter your code here\n",
    "    # Enter your code here\n",
    "    CorruptionScore2 += SVCclassifier.score(testX, testY) * 100\n",
    "    print(\"Option 2 accuracy score\", (loops + 1), \" =\", SVCclassifier.score(testX, testY) * 100, \"\\b%\")\n",
    "\n",
    "# just for readability\n",
    "print(\"\\n\\n\")\n",
    "print(\"Option 1 average accuracy =\", (CorruptionScore1/maxLoops), \"\\b%\")\n",
    "print(\"Option 2 average accuracy =\", (CorruptionScore2/maxLoops), \"\\b%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "I shortened down the printed stats to only reveal the accuracy score for readability.\n",
    "As seen above, CorruptionOption = 2: real power AND voltage magnitude consistantly leads to a significantly higher accuracy rate. This is, again, most likely due to having more irronious numbers adding up which makes spotting false data easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
